{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "This will be the cell that we use to get random game boards and have Stockfish analyze\n",
    "\n",
    "- The Chess engine will generate a random board state\n",
    "- Stockfish will take that random board state and return an evaluation for white's position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chess\n",
    "import chess.engine\n",
    "import random\n",
    "import numpy\n",
    "\n",
    "\n",
    "# this function will create our x (board)\n",
    "def random_board(max_moves=200):  # 200 should be enough moves to give enough data for AI\n",
    "  board = chess.Board()\n",
    "  depth = random.randrange(0, 200)\n",
    "\n",
    "  for _ in range(depth):\n",
    "    all_possible_moves = list(board.legal_moves)\n",
    "    move = random.choice(all_possible_moves)\n",
    "    board.push(move)\n",
    "    if board.is_game_over():\n",
    "      break\n",
    "\n",
    "  return board\n",
    "\n",
    "# this function will create our f(x) (score)\n",
    "def stockfish(board, depth):\n",
    "  with chess.engine.SimpleEngine.popen_uci(\"/usr/games/stockfish\") as sf:\n",
    "    result = sf.analyse(board, chess.engine.Limit(depth=depth))\n",
    "    score = result['score'].white().score()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "board = random_board()\n",
    "board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stockfish(board, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squares_index = {\n",
    "  'a': 0,\n",
    "  'b': 1,\n",
    "  'c': 2,\n",
    "  'd': 3,\n",
    "  'e': 4,\n",
    "  'f': 5,\n",
    "  'g': 6,\n",
    "  'h': 7\n",
    "}\n",
    "\n",
    "\n",
    "# example: h3 -> 17\n",
    "def square_to_index(square):\n",
    "  letter = chess.square_name(square)\n",
    "  return 8 - int(letter[1]), squares_index[letter[0]]\n",
    "\n",
    "\n",
    "def split_dims(board):\n",
    "  # this is the 3d matrix\n",
    "  board3d = numpy.zeros((14, 8, 8), dtype=numpy.int8)\n",
    "\n",
    "  # here we add the pieces's view on the matrix\n",
    "  for piece in chess.PIECE_TYPES:\n",
    "    for square in board.pieces(piece, chess.WHITE):\n",
    "      idx = numpy.unravel_index(square, (8, 8))\n",
    "      board3d[piece - 1][7 - idx[0]][idx[1]] = 1\n",
    "    for square in board.pieces(piece, chess.BLACK):\n",
    "      idx = numpy.unravel_index(square, (8, 8))\n",
    "      board3d[piece + 5][7 - idx[0]][idx[1]] = 1\n",
    "\n",
    "  # add attacks and valid moves too\n",
    "  # so the network knows what is being attacked\n",
    "  aux = board.turn\n",
    "  board.turn = chess.WHITE\n",
    "  for move in board.legal_moves:\n",
    "      i, j = square_to_index(move.to_square)\n",
    "      board3d[12][i][j] = 1\n",
    "  board.turn = chess.BLACK\n",
    "  for move in board.legal_moves:\n",
    "      i, j = square_to_index(move.to_square)\n",
    "      board3d[13][i][j] = 1\n",
    "  board.turn = aux\n",
    "\n",
    "  return board3d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This code generates and saves our data into a numpy file\n",
    "- Generates random board\n",
    "- Gets Stockfish eval\n",
    "- Turns board into a 3d numpy array\n",
    "- Saves eval and board array's to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boards = numpy.arange(89600000, dtype=numpy.int8).reshape(100000, 14, 8, 8)\n",
    "evals = numpy.arange(100000, dtype=numpy.int32)\n",
    "\n",
    "for i in range(100000):\n",
    "    board = random_board()\n",
    "    eval = stockfish(board, 10) \n",
    "\n",
    "    eval = eval if eval else 0\n",
    "    \n",
    "    boards[i] = split_dims(board)\n",
    "    evals[i] = eval\n",
    "\n",
    "numpy.savez('data.npz', b=boards, v=evals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load In Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "def get_dataset():\n",
    "    data = numpy.load('data.npz')\n",
    "    b, v = data['b'], data['v']\n",
    "    v = numpy.asarray( v / abs(v).max() / 2 + 0.5, dtype=numpy.float32)\n",
    "\n",
    "    return b, v\n",
    "\n",
    "def get_test_dataset():\n",
    "    data = numpy.load('testdata.npz')\n",
    "    b, v = data['b'], data['v']\n",
    "    v = numpy.asarray( v / abs(v).max() / 2 + 0.5, dtype=numpy.float32)\n",
    "\n",
    "    return b, v\n",
    "\n",
    "\n",
    "x_train, y_train = get_dataset()\n",
    "y_train.resize(100000)\n",
    "\n",
    "x_test, y_test = get_test_dataset()\n",
    "y_test.resize(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-30 22:15:26.649565: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-30 22:15:26.649618: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-30 22:15:26.649634: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-30 22:15:26.655444: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-30 22:15:27.974760: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-30 22:15:27.980506: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-30 22:15:27.980569: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-30 22:15:27.981729: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-30 22:15:27.981779: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-30 22:15:27.981807: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-30 22:15:28.227690: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-30 22:15:28.227748: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-30 22:15:28.227756: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1977] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-11-30 22:15:28.227795: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-30 22:15:28.227822: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5578 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:2b:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "inputs = layers.Input(shape=(14,8,8))\n",
    "\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, padding='same', activation=tf.nn.sigmoid)(inputs)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, padding='same', activation=tf.nn.sigmoid)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv2D(filters=64, kernel_size=3, padding='same', activation=tf.nn.sigmoid)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv2D(filters=64, kernel_size=3, padding='same', activation=tf.nn.sigmoid)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv2D(filters=128, kernel_size=3, padding='same', activation=tf.nn.sigmoid)(x)\n",
    "\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(32, tf.nn.sigmoid)(x)\n",
    "outputs = layers.Dense(1, tf.nn.sigmoid)(x)\n",
    "\n",
    "model = tf.keras.models.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 14, 8, 8)]        0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 14, 8, 32)         2336      \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 14, 8, 32)         128       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 14, 8, 32)         9248      \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 14, 8, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 14, 8, 64)         18496     \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 14, 8, 64)         256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 14, 8, 64)         36928     \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 14, 8, 64)         256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 14, 8, 128)        73856     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 14336)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                458784    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 600449 (2.29 MB)\n",
      "Trainable params: 600065 (2.29 MB)\n",
      "Non-trainable params: 384 (1.50 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "              loss=tf.keras.losses.MeanSquaredError())\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit/Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-30 22:15:28.871823: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-30 22:15:30.018241: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8700\n",
      "2023-11-30 22:15:30.188083: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-11-30 22:15:30.813944: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f31018c5a70 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-11-30 22:15:30.813993: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3070, Compute Capability 8.6\n",
      "2023-11-30 22:15:30.819117: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-11-30 22:15:30.885837: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3122/3125 [============================>.] - ETA: 0s - loss: 2.8562e-04INFO:tensorflow:Assets written to: /tmp/checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3125/3125 [==============================] - 28s 8ms/step - loss: 2.8546e-04 - val_loss: 1.3854e-04\n",
      "Epoch 2/10\n",
      "3125/3125 [==============================] - ETA: 0s - loss: 1.2499e-04INFO:tensorflow:Assets written to: /tmp/checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3125/3125 [==============================] - 23s 7ms/step - loss: 1.2499e-04 - val_loss: 1.3415e-04\n",
      "Epoch 3/10\n",
      "3120/3125 [============================>.] - ETA: 0s - loss: 1.1018e-04INFO:tensorflow:Assets written to: /tmp/checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3125/3125 [==============================] - 22s 7ms/step - loss: 1.1021e-04 - val_loss: 1.0351e-04\n",
      "Epoch 4/10\n",
      "3120/3125 [============================>.] - ETA: 0s - loss: 1.0306e-04INFO:tensorflow:Assets written to: /tmp/checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3125/3125 [==============================] - 22s 7ms/step - loss: 1.0307e-04 - val_loss: 1.0236e-04\n",
      "Epoch 5/10\n",
      "3125/3125 [==============================] - 21s 7ms/step - loss: 1.0042e-04 - val_loss: 1.3951e-04\n",
      "Epoch 6/10\n",
      "3125/3125 [==============================] - 21s 7ms/step - loss: 9.7642e-05 - val_loss: 1.0648e-04\n",
      "Epoch 7/10\n",
      "3125/3125 [==============================] - 21s 7ms/step - loss: 9.5362e-05 - val_loss: 1.0810e-04\n",
      "Epoch 8/10\n",
      "3117/3125 [============================>.] - ETA: 0s - loss: 9.4165e-05INFO:tensorflow:Assets written to: /tmp/checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3125/3125 [==============================] - 23s 7ms/step - loss: 9.4162e-05 - val_loss: 9.7827e-05\n",
      "Epoch 9/10\n",
      "3121/3125 [============================>.] - ETA: 0s - loss: 9.2880e-05INFO:tensorflow:Assets written to: /tmp/checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3125/3125 [==============================] - 22s 7ms/step - loss: 9.2871e-05 - val_loss: 9.2164e-05\n",
      "Epoch 10/10\n",
      "3117/3125 [============================>.] - ETA: 0s - loss: 9.1962e-05INFO:tensorflow:Assets written to: /tmp/checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3125/3125 [==============================] - 22s 7ms/step - loss: 9.1907e-05 - val_loss: 9.1617e-05\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "import datetime\n",
    "\n",
    "name = \"Chess-CNN-Model\"\n",
    "log_dir = \"logs/\" + name + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tb = tf.keras.callbacks.TensorBoard(log_dir=log_dir)\n",
    "\n",
    "checkpoint_filepath = '/tmp/checkpoint/'\n",
    "callbacks = [\n",
    "    tb,\n",
    "\n",
    "    ModelCheckpoint(\n",
    "        filepath = checkpoint_filepath,\n",
    "        save_weights_only=False,\n",
    "        save_best_only = True,\n",
    "    )\n",
    "]\n",
    "\n",
    "model.fit(x_train, y_train, validation_data=(x_test, y_test), batch_size=32, epochs=10, verbose=1, validation_split=0.1, callbacks=callbacks)\n",
    "\n",
    "model.save('models/model' + str(datetime.datetime.now()) + '.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3125/3125 [==============================] - 6s 2ms/step - loss: 9.1617e-05\n",
      "0.009161710477201268\n"
     ]
    }
   ],
   "source": [
    "print(model.evaluate(x_test, y_test, batch_size=32, verbose=1, callbacks=callbacks)*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
