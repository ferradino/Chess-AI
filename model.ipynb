{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model.ipynb\n",
    "This file contains all the necessary features to build our model from scratch:\n",
    "- Generating and Saving Data\n",
    "- Loading the Data\n",
    "- Building the Model Structure\n",
    "- Compiling the Model\n",
    "- Fitting/Training the Model\n",
    "- Saving the Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chess\n",
    "import chess.engine\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# This creates randoms boards we will feed to our model\n",
    "def gen_random_board(max_moves=200):\n",
    "    board = chess.Board()\n",
    "    depth = random.randrange(0, max_moves)\n",
    "\n",
    "    for _ in range(depth):\n",
    "        all_possible_moves = list(board.legal_moves)\n",
    "        move = random.choice(all_possible_moves)\n",
    "        board.push(move)\n",
    "        if board.is_game_over():\n",
    "            break\n",
    "    \n",
    "    return board\n",
    "\n",
    "# This returns the Stockfish eval which we will feed to our model\n",
    "def stockfish(board, depth):\n",
    "    with chess.engine.SimpleEngine.popen_uci(\"/usr/games/stockfish\") as sf:\n",
    "        result = sf.analyse(board, chess.engine.Limit(depth=depth))\n",
    "        score = result['score'].white().score()\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "board = gen_random_board()\n",
    "board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stockfish(board, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squares_index = {\n",
    "    'a': 0,\n",
    "    'b': 1,\n",
    "    'c': 2,\n",
    "    'd': 3,\n",
    "    'e': 4,\n",
    "    'f': 5,\n",
    "    'g': 6,\n",
    "    'h': 7,\n",
    "}\n",
    "\n",
    "def square_to_index(square):\n",
    "    letter = chess.square_name(square)\n",
    "    return 8 - int(letter[1]), squares_index[letter[0]]\n",
    "\n",
    "def convert_to_3d(board):\n",
    "    board3d = np.zeros((14,8,8), dtype=np.int8)\n",
    "\n",
    "    for piece in chess.PIECE_TYPES:\n",
    "        for square in board.pieces(piece, chess.WHITE):\n",
    "            idx = np.unravel_index(square, (8,8))\n",
    "            board3d[piece - 1][7 - idx[0]][idx[1]] = 1\n",
    "        for square in board.pieces(piece, chess.BLACK):\n",
    "            idx = np.unravel_index(square, (8,8))\n",
    "            board3d[piece + 5][7 - idx[0]][idx[1]] = 1\n",
    "\n",
    "    aux = board.turn\n",
    "    board.turn = chess.WHITE\n",
    "    for move in board.legal_moves:\n",
    "        i, j, = square_to_index(move.to_square)\n",
    "        board3d[12][i][j] = 1\n",
    "    board.turn = chess.BLACK\n",
    "    for move in board.legal_moves:\n",
    "        i, j = square_to_index(move.to_square)\n",
    "        board3d[13][i][j] = 1\n",
    "    board.turn = aux\n",
    "    \n",
    "    return board3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boards = np.arange(89600000, dtype=np.int8).reshape(100000, 14, 8, 8)\n",
    "evals = np.arange(100000, dtype=np.int32)\n",
    "\n",
    "for i in range(100000):\n",
    "    board = gen_random_board()\n",
    "    eval = stockfish(board, 10)\n",
    "\n",
    "    eval = eval if eval else 0\n",
    "    \n",
    "    boards[i] = convert_to_3d(board)\n",
    "    evals[i] = eval\n",
    "\n",
    "file_name = 'data.npz'\n",
    "np.savez(os.path.join('data', file_name), b=boards, v=evals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "file_name = 'data.npz'  # Change this to use a different dataset from the data folder\n",
    "\n",
    "def get_dataset():\n",
    "    data = np.load(os.path.join('data', file_name))\n",
    "    b, v = data['b'], data['v']\n",
    "    v = np.asarray( v / abs(v).max() / 2 + 0.5, dtype=np.float32)\n",
    "\n",
    "    return b, v\n",
    "\n",
    "x_train, y_train = get_dataset()\n",
    "\n",
    "def get_test_dataset():\n",
    "    data = np.load('data/testdata.npz')\n",
    "    b, v = data['b'], data['v']\n",
    "    v = np.asarray( v / abs(v).max() / 2 + 0.5, dtype=np.float32)\n",
    "\n",
    "    return b, v\n",
    "\n",
    "x_test, y_test = get_test_dataset()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AI Convolution Neural Network Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 21:12:21.525468: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-04 21:12:21.525518: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-04 21:12:21.525557: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 14, 8, 8)]        0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 14, 8, 32)         2336      \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 14, 8, 32)         128       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 14, 8, 32)         9248      \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 14, 8, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 14, 8, 64)         18496     \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 14, 8, 64)         256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 14, 8, 64)         36928     \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 14, 8, 64)         256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 14, 8, 128)        73856     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 14336)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                458784    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 600449 (2.29 MB)\n",
      "Trainable params: 600065 (2.29 MB)\n",
      "Non-trainable params: 384 (1.50 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as layers\n",
    "\n",
    "inputs = layers.Input(shape=(14, 8, 8))\n",
    "\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, padding='same', activation=tf.nn.sigmoid)(inputs)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, padding='same', activation=tf.nn.sigmoid)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv2D(filters=64, kernel_size=3, padding='same', activation=tf.nn.sigmoid)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv2D(filters=64, kernel_size=3, padding='same', activation=tf.nn.sigmoid)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv2D(filters=128, kernel_size=3, padding='same', activation=tf.nn.sigmoid)(x)\n",
    "\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(32, tf.nn.sigmoid)(x)\n",
    "\n",
    "outputs = layers.Dense(1, tf.nn.sigmoid)(x)\n",
    "\n",
    "model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "              loss=tf.keras.losses.MeanSquaredError())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit/Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Data cardinality is ambiguous:\n  x sizes: 100000\n  y sizes: 89600000\nMake sure all arrays contain the same number of samples.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/ferradino/Chess-AI/model.ipynb Cell 16\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/ferradino/Chess-AI/model.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m checkpoint_filepath \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/tmp/checkpoint/\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/ferradino/Chess-AI/model.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m callbacks \u001b[39m=\u001b[39m [\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/ferradino/Chess-AI/model.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m     tb,\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/ferradino/Chess-AI/model.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m     \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/ferradino/Chess-AI/model.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m     )\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/ferradino/Chess-AI/model.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m ]\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/ferradino/Chess-AI/model.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(x_train, y_train, batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m, epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, validation_split\u001b[39m=\u001b[39;49m\u001b[39m0.1\u001b[39;49m, callbacks\u001b[39m=\u001b[39;49mcallbacks, validation_data\u001b[39m=\u001b[39;49m(x_test, y_test), validation_batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/engine/data_adapter.py:1960\u001b[0m, in \u001b[0;36m_check_data_cardinality\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   1953\u001b[0m     msg \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m  \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m sizes: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1954\u001b[0m         label,\n\u001b[1;32m   1955\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(\n\u001b[1;32m   1956\u001b[0m             \u001b[39mstr\u001b[39m(i\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mflatten(single_data)\n\u001b[1;32m   1957\u001b[0m         ),\n\u001b[1;32m   1958\u001b[0m     )\n\u001b[1;32m   1959\u001b[0m msg \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mMake sure all arrays contain the same number of samples.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1960\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n",
      "\u001b[0;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 100000\n  y sizes: 89600000\nMake sure all arrays contain the same number of samples."
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "\n",
    "log_name = 'Chess-CNN-Model' + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "log_dir = os.path.join('logs', log_name)\n",
    "tb = TensorBoard(log_dir=log_dir) \n",
    "\n",
    "checkpoint_filepath = '/tmp/checkpoint/'\n",
    "\n",
    "callbacks = [\n",
    "    tb,\n",
    "    \n",
    "    ModelCheckpoint(\n",
    "        filepath = checkpoint_filepath,\n",
    "        save_weights_only = False,\n",
    "        save_best_only = True,\n",
    "    )\n",
    "]\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=32, epochs=10, verbose=1, validation_split=0.1, callbacks=callbacks, validation_data=(x_test, y_test), validation_batch_size=32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model\n",
    "- If we like the performance of our model, we should save it\n",
    "- The following line of code saves our model to a '.keras' file\n",
    "    - We can load this back in and train it more\n",
    "    - Or we can load it into our chess game and play against it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = 'model' +  str(datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")) + '.keras'\n",
    "model.save(os.path.join('model', model_file))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
