{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model.ipynb\n",
    "This file contains all the necessary features to build our model from scratch:\n",
    "- Generating and Saving Data\n",
    "- Loading the Data\n",
    "- Building the Model Structure\n",
    "- Compiling the Model\n",
    "- Fitting/Training the Model\n",
    "- Saving the Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chess\n",
    "import chess.engine\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# This creates randoms boards we will feed to our model\n",
    "def gen_random_board(max_moves=200):\n",
    "    board = chess.Board()\n",
    "    depth = random.randrange(0, max_moves)\n",
    "\n",
    "    for _ in range(depth):\n",
    "        all_possible_moves = list(board.legal_moves)\n",
    "        move = random.choice(all_possible_moves)\n",
    "        board.push(move)\n",
    "        if board.is_game_over():\n",
    "            break\n",
    "    \n",
    "    return board\n",
    "\n",
    "# This returns the Stockfish eval which we will feed to our model\n",
    "def stockfish(board, depth):\n",
    "    with chess.engine.SimpleEngine.popen_uci(\"/usr/games/stockfish\") as sf:\n",
    "        result = sf.analyse(board, chess.engine.Limit(depth=depth))\n",
    "        score = result['score'].white().score()\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "board = gen_random_board()\n",
    "board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stockfish(board, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squares_index = {\n",
    "    'a': 0,\n",
    "    'b': 1,\n",
    "    'c': 2,\n",
    "    'd': 3,\n",
    "    'e': 4,\n",
    "    'f': 5,\n",
    "    'g': 6,\n",
    "    'h': 7,\n",
    "}\n",
    "\n",
    "def square_to_index(square):\n",
    "    letter = chess.square_name(square)\n",
    "    return 8 - int(letter[1]), squares_index[letter[0]]\n",
    "\n",
    "def convert_to_3d(board):\n",
    "    board3d = np.zeros((14,8,8), dtype=np.int8)\n",
    "\n",
    "    for piece in chess.PIECE_TYPES:\n",
    "        for square in board.pieces(piece, chess.WHITE):\n",
    "            idx = np.unravel_index(square, (8,8))\n",
    "            board3d[piece - 1][7 - idx[0]][idx[1]] = 1\n",
    "        for square in board.pieces(piece, chess.BLACK):\n",
    "            idx = np.unravel_index(square, (8,8))\n",
    "            board3d[piece + 5][7 - idx[0]][idx[1]] = 1\n",
    "\n",
    "    aux = board.turn\n",
    "    board.turn = chess.WHITE\n",
    "    for move in board.legal_moves:\n",
    "        i, j, = square_to_index(move.to_square)\n",
    "        board3d[12][i][j] = 1\n",
    "    board.turn = chess.BLACK\n",
    "    for move in board.legal_moves:\n",
    "        i, j = square_to_index(move.to_square)\n",
    "        board3d[13][i][j] = 1\n",
    "    board.turn = aux\n",
    "    \n",
    "    return board3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boards = np.arange(89600000, dtype=np.int8).reshape(100000, 14, 8, 8)\n",
    "evals = np.arange(100000, dtype=np.int32)\n",
    "\n",
    "for i in range(100000):\n",
    "    board = gen_random_board()\n",
    "    eval = stockfish(board, 10)\n",
    "\n",
    "    eval = eval if eval else 0\n",
    "    \n",
    "    boards[i] = convert_to_3d(board)\n",
    "    evals[i] = eval\n",
    "\n",
    "file_name = 'data.npz'\n",
    "np.savez(os.path.join('data', file_name), b=boards, v=evals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "file_name = 'data.npz'  # Change this to use a different dataset from the data folder\n",
    "\n",
    "def get_dataset():\n",
    "    data = np.load(os.path.join('data', file_name))\n",
    "    b, v = data['b'], data['v']\n",
    "    v = np.asarray( v / abs(v).max() / 2 + 0.5, dtype=np.float32)\n",
    "\n",
    "    return b, v\n",
    "\n",
    "x_train, y_train = get_dataset()\n",
    "y_train.resize(100000)\n",
    "\n",
    "def get_test_dataset():\n",
    "    data = np.load(os.path.join('data', file_name))\n",
    "    b, v = data['b'], data['v']\n",
    "    v = np.asarray( v / abs(v).max() / 2 + 0.5, dtype=np.float32)\n",
    "\n",
    "    return b, v\n",
    "\n",
    "x_test, y_test = get_test_dataset()\n",
    "y_test.resize(100000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AI Convolution Neural Network Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 14, 8, 8)]        0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 14, 8, 32)         2336      \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 14, 8, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 14, 8, 32)         9248      \n",
      "                                                                 \n",
      " batch_normalization_5 (Bat  (None, 14, 8, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 14, 8, 64)         18496     \n",
      "                                                                 \n",
      " batch_normalization_6 (Bat  (None, 14, 8, 64)         256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 14, 8, 64)         36928     \n",
      "                                                                 \n",
      " batch_normalization_7 (Bat  (None, 14, 8, 64)         256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 14, 8, 128)        73856     \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 14336)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                458784    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 600449 (2.29 MB)\n",
      "Trainable params: 600065 (2.29 MB)\n",
      "Non-trainable params: 384 (1.50 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as layers\n",
    "\n",
    "inputs = layers.Input(shape=(14, 8, 8))\n",
    "\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, padding='same', activation=tf.nn.sigmoid)(inputs)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, padding='same', activation=tf.nn.sigmoid)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv2D(filters=64, kernel_size=3, padding='same', activation=tf.nn.sigmoid)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv2D(filters=64, kernel_size=3, padding='same', activation=tf.nn.sigmoid)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv2D(filters=128, kernel_size=3, padding='same', activation=tf.nn.sigmoid)(x)\n",
    "\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(32, tf.nn.sigmoid)(x)\n",
    "\n",
    "outputs = layers.Dense(1, tf.nn.sigmoid)(x)\n",
    "\n",
    "model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "              loss=tf.keras.losses.MeanSquaredError())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit/Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3118/3125 [============================>.] - ETA: 0s - loss: 1.6711e-04INFO:tensorflow:Assets written to: /tmp/checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3125/3125 [==============================] - 23s 6ms/step - loss: 1.6705e-04 - val_loss: 1.1874e-04\n",
      "Epoch 2/10\n",
      "3114/3125 [============================>.] - ETA: 0s - loss: 1.1639e-04INFO:tensorflow:Assets written to: /tmp/checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3125/3125 [==============================] - 18s 6ms/step - loss: 1.1637e-04 - val_loss: 1.0836e-04\n",
      "Epoch 3/10\n",
      "3120/3125 [============================>.] - ETA: 0s - loss: 1.0718e-04INFO:tensorflow:Assets written to: /tmp/checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.0719e-04 - val_loss: 9.8711e-05\n",
      "Epoch 4/10\n",
      "3115/3125 [============================>.] - ETA: 0s - loss: 1.0194e-04INFO:tensorflow:Assets written to: /tmp/checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3125/3125 [==============================] - 18s 6ms/step - loss: 1.0197e-04 - val_loss: 9.5707e-05\n",
      "Epoch 5/10\n",
      "3125/3125 [==============================] - 17s 5ms/step - loss: 9.9112e-05 - val_loss: 9.5886e-05\n",
      "Epoch 6/10\n",
      "3116/3125 [============================>.] - ETA: 0s - loss: 9.6505e-05INFO:tensorflow:Assets written to: /tmp/checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3125/3125 [==============================] - 19s 6ms/step - loss: 9.6536e-05 - val_loss: 9.5643e-05\n",
      "Epoch 7/10\n",
      "3117/3125 [============================>.] - ETA: 0s - loss: 9.4614e-05INFO:tensorflow:Assets written to: /tmp/checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3125/3125 [==============================] - 19s 6ms/step - loss: 9.4606e-05 - val_loss: 9.3459e-05\n",
      "Epoch 8/10\n",
      "3116/3125 [============================>.] - ETA: 0s - loss: 9.3204e-05INFO:tensorflow:Assets written to: /tmp/checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3125/3125 [==============================] - 19s 6ms/step - loss: 9.3249e-05 - val_loss: 9.2233e-05\n",
      "Epoch 9/10\n",
      "3114/3125 [============================>.] - ETA: 0s - loss: 9.1634e-05INFO:tensorflow:Assets written to: /tmp/checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3125/3125 [==============================] - 19s 6ms/step - loss: 9.1828e-05 - val_loss: 8.9276e-05\n",
      "Epoch 10/10\n",
      "3117/3125 [============================>.] - ETA: 0s - loss: 9.0523e-05INFO:tensorflow:Assets written to: /tmp/checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3125/3125 [==============================] - 19s 6ms/step - loss: 9.0530e-05 - val_loss: 8.8839e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f85f0534af0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "\n",
    "log_name = 'Chess-CNN-Model'\n",
    "log_dir = os.path.join('logs', log_name)\n",
    "tb = TensorBoard(log_dir=log_dir) \n",
    "\n",
    "checkpoint_filepath = '/tmp/checkpoint/'\n",
    "\n",
    "callbacks = [\n",
    "    tb,\n",
    "    \n",
    "    ModelCheckpoint(\n",
    "        filepath = checkpoint_filepath,\n",
    "        save_weights_only = False,\n",
    "        save_best_only = True,\n",
    "    )\n",
    "]\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=32, epochs=10, verbose=1, validation_split=0.1, callbacks=callbacks, validation_data=(x_test, y_test), validation_batch_size=32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model\n",
    "- If we like the performance of our model, we should save it\n",
    "- The following line of code saves our model to a '.keras' file\n",
    "    - We can load this back in and train it more\n",
    "    - Or we can load it into our chess game and play against it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('models/model.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
